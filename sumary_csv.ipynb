{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pickle import NONE\n",
    "from re import T\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import os \n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ChnSentiCorp': {'mbert': {'Attention_Suff': 1.0902327957363036, 'Scaled_Attention_Suff': 1.0884435049783747, 'Gradients_Suff': 1.0483311770328323, 'Integrated_Gradients_Suff': 1.1026349831942344, 'Deeplift_Suff': 1.025998869133796, 'Attention_Comp': 1.3710924885883555, 'Scaled_Attention_Comp': 1.3789226438370283, 'Gradients_Comp': 1.156845532531631, 'Integrated_Gradients_Comp': 1.3241123432705728, 'Deeplift_Comp': 1.1598957879910066, 'Accuracy': 0.8577777777777771}, 'zhbert': {'Attention_Suff': 1.1186359490734263, 'Scaled_Attention_Suff': 1.1236845435293923, 'Gradients_Suff': 0.9976570862899498, 'Integrated_Gradients_Suff': 1.0772416350726395, 'Deeplift_Suff': 0.9511550052472773, 'Attention_Comp': 1.1876611990674635, 'Scaled_Attention_Comp': 1.1801661231830363, 'Gradients_Comp': 1.0394625200358314, 'Integrated_Gradients_Comp': 1.2453264958711667, 'Deeplift_Comp': 1.0270209744638243, 'Accuracy': 0.901944444444444}}, 'multirc': {'mbert': {'Attention_Suff': 1.1528163924002583, 'Scaled_Attention_Suff': 1.160154956255558, 'Gradients_Suff': 1.0001782820153244, 'Integrated_Gradients_Suff': 1.0782598688552258, 'Deeplift_Suff': 0.9993364021713032, 'Attention_Comp': 0.9955666407107236, 'Scaled_Attention_Comp': 0.992904356248007, 'Gradients_Comp': 1.0018762830182584, 'Integrated_Gradients_Comp': 1.0047978625144316, 'Deeplift_Comp': 1.0020655492592467, 'F1': 0.708081756873426}, 'bert': {'Attention_Suff': 1.295512460541634, 'Scaled_Attention_Suff': 1.2872221467110898, 'Gradients_Suff': 1.0363704378054417, 'Integrated_Gradients_Suff': 1.1011344793996825, 'Deeplift_Suff': 0.9856377618396626, 'Attention_Comp': 1.0066199174970396, 'Scaled_Attention_Comp': 1.009889976081217, 'Gradients_Comp': 0.9991115138577739, 'Integrated_Gradients_Comp': 0.9994490412652345, 'Deeplift_Comp': 1.0004289512679125, 'F1': 0.680454485654535}}, 'ant': {'mbert': {'Attention_Suff': 1.0477384467759994, 'Scaled_Attention_Suff': 1.0449974576786865, 'Gradients_Suff': 0.9872483912617476, 'Integrated_Gradients_Suff': 1.0048719339127243, 'Deeplift_Suff': 0.9655902202994344, 'Attention_Comp': 1.1037677225925988, 'Scaled_Attention_Comp': 1.113315858846973, 'Gradients_Comp': 0.9932145224193266, 'Integrated_Gradients_Comp': 0.9806456166416007, 'Deeplift_Comp': 1.0196784787484527, 'Accuracy': 0.912716912716912}, 'zhbert': {'Attention_Suff': 1.0243519983478813, 'Scaled_Attention_Suff': 1.038452472139083, 'Gradients_Suff': 0.9815883008520067, 'Integrated_Gradients_Suff': 0.974429650586753, 'Deeplift_Suff': 0.9984249355334712, 'Attention_Comp': 1.0389534272744658, 'Scaled_Attention_Comp': 1.0276156119427946, 'Gradients_Comp': 1.0074105650526328, 'Integrated_Gradients_Comp': 1.0217447124035852, 'Deeplift_Comp': 1.0195815720060808, 'Accuracy': 0.722610722610722}}, 'agnews': {'mbert': {'Attention_Suff': 1.3018478196445673, 'Scaled_Attention_Suff': 1.303969427059124, 'Gradients_Suff': 1.0151901245198574, 'Integrated_Gradients_Suff': 1.2035095073555637, 'Deeplift_Suff': 1.0409249387751582, 'Attention_Comp': 1.6327321649621618, 'Scaled_Attention_Comp': 1.6322149420626877, 'Gradients_Comp': 1.231301912420742, 'Integrated_Gradients_Comp': 1.5172697211566961, 'Deeplift_Comp': 1.1937422579936299, 'F1': 0.9303252066670791}}, 'csl': {'zhbert': {'Attention_Suff': 1.2127844943573733, 'Scaled_Attention_Suff': 1.216695302106607, 'Gradients_Suff': 0.9405321911658495, 'Integrated_Gradients_Suff': 0.9936711844562186, 'Deeplift_Suff': 1.021235237336812, 'Attention_Comp': 0.9950494609991279, 'Scaled_Attention_Comp': 0.9947986854193601, 'Gradients_Comp': 0.999208884713569, 'Integrated_Gradients_Comp': 0.9996401197257241, 'Deeplift_Comp': 0.9991146393430018, 'Accuracy': 0.8352222222222221}}, 'evinf': {'bert': {'Attention_Suff': 1.5363029592752437, 'Scaled_Attention_Suff': 1.5485558557610177, 'Gradients_Suff': 1.094252755557506, 'Integrated_Gradients_Suff': 1.2081617718188984, 'Deeplift_Suff': 0.9886237483761672, 'Attention_Comp': 1.2677058005598023, 'Scaled_Attention_Comp': 1.267693591134925, 'Gradients_Comp': 1.0446644022145226, 'Integrated_Gradients_Comp': 1.1501872818912802, 'Deeplift_Comp': 1.043107766092951, 'F1': 0.6262390217157291}}}\n"
     ]
    }
   ],
   "source": [
    "with open('results_summary.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "ChnSentiCorp\n",
      "mbert\n",
      "{'Attention_Suff': 1.0902327957363036, 'Scaled_Attention_Suff': 1.0884435049783747, 'Gradients_Suff': 1.0483311770328323, 'Integrated_Gradients_Suff': 1.1026349831942344, 'Deeplift_Suff': 1.025998869133796, 'Attention_Comp': 1.3710924885883555, 'Scaled_Attention_Comp': 1.3789226438370283, 'Gradients_Comp': 1.156845532531631, 'Integrated_Gradients_Comp': 1.3241123432705728, 'Deeplift_Comp': 1.1598957879910066, 'Accuracy': 0.8577777777777771}\n",
      "zhbert\n",
      "{'Attention_Suff': 1.1186359490734263, 'Scaled_Attention_Suff': 1.1236845435293923, 'Gradients_Suff': 0.9976570862899498, 'Integrated_Gradients_Suff': 1.0772416350726395, 'Deeplift_Suff': 0.9511550052472773, 'Attention_Comp': 1.1876611990674635, 'Scaled_Attention_Comp': 1.1801661231830363, 'Gradients_Comp': 1.0394625200358314, 'Integrated_Gradients_Comp': 1.2453264958711667, 'Deeplift_Comp': 1.0270209744638243, 'Accuracy': 0.901944444444444}\n",
      "        Attention_Suff  Scaled_Attention_Suff  Gradients_Suff  \\\n",
      "mbert         1.090233               1.088444        1.048331   \n",
      "zhbert        1.118636               1.123685        0.997657   \n",
      "\n",
      "        Integrated_Gradients_Suff  Deeplift_Suff  Attention_Comp  \\\n",
      "mbert                    1.102635       1.025999        1.371092   \n",
      "zhbert                   1.077242       0.951155        1.187661   \n",
      "\n",
      "        Scaled_Attention_Comp  Gradients_Comp  Integrated_Gradients_Comp  \\\n",
      "mbert                1.378923        1.156846                   1.324112   \n",
      "zhbert               1.180166        1.039463                   1.245326   \n",
      "\n",
      "        Deeplift_Comp  Accuracy   model       dataset  \n",
      "mbert        1.159896  0.857778   mbert  ChnSentiCorp  \n",
      "zhbert       1.027021  0.901944  zhbert  ChnSentiCorp  \n",
      " \n",
      "multirc\n",
      "mbert\n",
      "{'Attention_Suff': 1.1528163924002583, 'Scaled_Attention_Suff': 1.160154956255558, 'Gradients_Suff': 1.0001782820153244, 'Integrated_Gradients_Suff': 1.0782598688552258, 'Deeplift_Suff': 0.9993364021713032, 'Attention_Comp': 0.9955666407107236, 'Scaled_Attention_Comp': 0.992904356248007, 'Gradients_Comp': 1.0018762830182584, 'Integrated_Gradients_Comp': 1.0047978625144316, 'Deeplift_Comp': 1.0020655492592467, 'F1': 0.708081756873426}\n",
      "bert\n",
      "{'Attention_Suff': 1.295512460541634, 'Scaled_Attention_Suff': 1.2872221467110898, 'Gradients_Suff': 1.0363704378054417, 'Integrated_Gradients_Suff': 1.1011344793996825, 'Deeplift_Suff': 0.9856377618396626, 'Attention_Comp': 1.0066199174970396, 'Scaled_Attention_Comp': 1.009889976081217, 'Gradients_Comp': 0.9991115138577739, 'Integrated_Gradients_Comp': 0.9994490412652345, 'Deeplift_Comp': 1.0004289512679125, 'F1': 0.680454485654535}\n",
      "       Attention_Suff  Scaled_Attention_Suff  Gradients_Suff  \\\n",
      "mbert        1.152816               1.160155        1.000178   \n",
      "bert         1.295512               1.287222        1.036370   \n",
      "\n",
      "       Integrated_Gradients_Suff  Deeplift_Suff  Attention_Comp  \\\n",
      "mbert                   1.078260       0.999336        0.995567   \n",
      "bert                    1.101134       0.985638        1.006620   \n",
      "\n",
      "       Scaled_Attention_Comp  Gradients_Comp  Integrated_Gradients_Comp  \\\n",
      "mbert               0.992904        1.001876                   1.004798   \n",
      "bert                1.009890        0.999112                   0.999449   \n",
      "\n",
      "       Deeplift_Comp        F1  model  dataset  \n",
      "mbert       1.002066  0.708082  mbert  multirc  \n",
      "bert        1.000429  0.680454   bert  multirc  \n",
      " \n",
      "ant\n",
      "mbert\n",
      "{'Attention_Suff': 1.0477384467759994, 'Scaled_Attention_Suff': 1.0449974576786865, 'Gradients_Suff': 0.9872483912617476, 'Integrated_Gradients_Suff': 1.0048719339127243, 'Deeplift_Suff': 0.9655902202994344, 'Attention_Comp': 1.1037677225925988, 'Scaled_Attention_Comp': 1.113315858846973, 'Gradients_Comp': 0.9932145224193266, 'Integrated_Gradients_Comp': 0.9806456166416007, 'Deeplift_Comp': 1.0196784787484527, 'Accuracy': 0.912716912716912}\n",
      "zhbert\n",
      "{'Attention_Suff': 1.0243519983478813, 'Scaled_Attention_Suff': 1.038452472139083, 'Gradients_Suff': 0.9815883008520067, 'Integrated_Gradients_Suff': 0.974429650586753, 'Deeplift_Suff': 0.9984249355334712, 'Attention_Comp': 1.0389534272744658, 'Scaled_Attention_Comp': 1.0276156119427946, 'Gradients_Comp': 1.0074105650526328, 'Integrated_Gradients_Comp': 1.0217447124035852, 'Deeplift_Comp': 1.0195815720060808, 'Accuracy': 0.722610722610722}\n",
      "        Attention_Suff  Scaled_Attention_Suff  Gradients_Suff  \\\n",
      "mbert         1.047738               1.044997        0.987248   \n",
      "zhbert        1.024352               1.038452        0.981588   \n",
      "\n",
      "        Integrated_Gradients_Suff  Deeplift_Suff  Attention_Comp  \\\n",
      "mbert                    1.004872       0.965590        1.103768   \n",
      "zhbert                   0.974430       0.998425        1.038953   \n",
      "\n",
      "        Scaled_Attention_Comp  Gradients_Comp  Integrated_Gradients_Comp  \\\n",
      "mbert                1.113316        0.993215                   0.980646   \n",
      "zhbert               1.027616        1.007411                   1.021745   \n",
      "\n",
      "        Deeplift_Comp  Accuracy   model dataset  \n",
      "mbert        1.019678  0.912717   mbert     ant  \n",
      "zhbert       1.019582  0.722611  zhbert     ant  \n",
      " \n",
      "agnews\n",
      "mbert\n",
      "{'Attention_Suff': 1.3018478196445673, 'Scaled_Attention_Suff': 1.303969427059124, 'Gradients_Suff': 1.0151901245198574, 'Integrated_Gradients_Suff': 1.2035095073555637, 'Deeplift_Suff': 1.0409249387751582, 'Attention_Comp': 1.6327321649621618, 'Scaled_Attention_Comp': 1.6322149420626877, 'Gradients_Comp': 1.231301912420742, 'Integrated_Gradients_Comp': 1.5172697211566961, 'Deeplift_Comp': 1.1937422579936299, 'F1': 0.9303252066670791}\n",
      "       Attention_Suff  Scaled_Attention_Suff  Gradients_Suff  \\\n",
      "mbert        1.301848               1.303969         1.01519   \n",
      "\n",
      "       Integrated_Gradients_Suff  Deeplift_Suff  Attention_Comp  \\\n",
      "mbert                    1.20351       1.040925        1.632732   \n",
      "\n",
      "       Scaled_Attention_Comp  Gradients_Comp  Integrated_Gradients_Comp  \\\n",
      "mbert               1.632215        1.231302                    1.51727   \n",
      "\n",
      "       Deeplift_Comp        F1  model dataset  \n",
      "mbert       1.193742  0.930325  mbert  agnews  \n",
      " \n",
      "csl\n",
      "zhbert\n",
      "{'Attention_Suff': 1.2127844943573733, 'Scaled_Attention_Suff': 1.216695302106607, 'Gradients_Suff': 0.9405321911658495, 'Integrated_Gradients_Suff': 0.9936711844562186, 'Deeplift_Suff': 1.021235237336812, 'Attention_Comp': 0.9950494609991279, 'Scaled_Attention_Comp': 0.9947986854193601, 'Gradients_Comp': 0.999208884713569, 'Integrated_Gradients_Comp': 0.9996401197257241, 'Deeplift_Comp': 0.9991146393430018, 'Accuracy': 0.8352222222222221}\n",
      "        Attention_Suff  Scaled_Attention_Suff  Gradients_Suff  \\\n",
      "zhbert        1.212784               1.216695        0.940532   \n",
      "\n",
      "        Integrated_Gradients_Suff  Deeplift_Suff  Attention_Comp  \\\n",
      "zhbert                   0.993671       1.021235        0.995049   \n",
      "\n",
      "        Scaled_Attention_Comp  Gradients_Comp  Integrated_Gradients_Comp  \\\n",
      "zhbert               0.994799        0.999209                    0.99964   \n",
      "\n",
      "        Deeplift_Comp  Accuracy   model dataset  \n",
      "zhbert       0.999115  0.835222  zhbert     csl  \n",
      " \n",
      "evinf\n",
      "bert\n",
      "{'Attention_Suff': 1.5363029592752437, 'Scaled_Attention_Suff': 1.5485558557610177, 'Gradients_Suff': 1.094252755557506, 'Integrated_Gradients_Suff': 1.2081617718188984, 'Deeplift_Suff': 0.9886237483761672, 'Attention_Comp': 1.2677058005598023, 'Scaled_Attention_Comp': 1.267693591134925, 'Gradients_Comp': 1.0446644022145226, 'Integrated_Gradients_Comp': 1.1501872818912802, 'Deeplift_Comp': 1.043107766092951, 'F1': 0.6262390217157291}\n",
      "      Attention_Suff  Scaled_Attention_Suff  Gradients_Suff  \\\n",
      "bert        1.536303               1.548556        1.094253   \n",
      "\n",
      "      Integrated_Gradients_Suff  Deeplift_Suff  Attention_Comp  \\\n",
      "bert                   1.208162       0.988624        1.267706   \n",
      "\n",
      "      Scaled_Attention_Comp  Gradients_Comp  Integrated_Gradients_Comp  \\\n",
      "bert               1.267694        1.044664                   1.150187   \n",
      "\n",
      "      Deeplift_Comp        F1 model dataset  \n",
      "bert       1.043108  0.626239  bert   evinf  \n"
     ]
    }
   ],
   "source": [
    "data_df_list = []\n",
    "\n",
    "for data in loaded_dict.keys():\n",
    "     df_list = []\n",
    "     print(' ')\n",
    "     print(data)\n",
    "     for model in loaded_dict[data].keys():\n",
    "          print(model)\n",
    "          print(loaded_dict[data][model])\n",
    "          df = pd.DataFrame.from_dict(loaded_dict[data][model], orient='index', columns=[model])\n",
    "          df = df.transpose()\n",
    "          df['model'] = model\n",
    "          df_list.append(df)\n",
    "     result = pd.concat(df_list)\n",
    "     result['dataset'] = data\n",
    "     print(result)\n",
    "     data_df_list.append(result)\n",
    "\n",
    "result = pd.concat(data_df_list)\n",
    "result.insert(0, 'model', result.pop('model'))\n",
    "result = result.set_index('dataset',drop=True).round(3)\n",
    "\n",
    "result.to_csv('summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
