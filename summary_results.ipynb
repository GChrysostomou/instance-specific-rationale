{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import NONE\n",
    "from re import T\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(dataset,model_id):\n",
    "        \n",
    "        \n",
    "        model_folder = model_id + '_trained_models/' + dataset + '/'\n",
    "        faithful_folder = model_id + '_faithfulness/' + dataset\n",
    "        pred_folder = model_id + '_trained_models/' + dataset\n",
    "\n",
    "        file_path = f'./{model_id}_faithfulness/{dataset}/topk-faithfulness-scores-average-description.json'\n",
    "        topk = pd.read_json(file_path, orient ='index')\n",
    "        topk.rename(columns = {'AOPC - sufficiency':'AOPC_sufficiency', 'AOPC - comprehensiveness':'AOPC_comprehensiveness'}, inplace = True)\n",
    "\n",
    "        file_path = f'./{model_folder}/{model_id}_predictive_performances.json'\n",
    "        pred = pd.read_json(file_path)\n",
    "        if dataset == 'ChnSentiCorp' or dataset == 'ant' or dataset == 'csl': pred_result = pred['mean-accuracy'].mean()\n",
    "        else: pred_result = pred['mean-f1'].mean()\n",
    "\n",
    "        suff = []\n",
    "        comp = []\n",
    "        suff_std = []\n",
    "        comp_std = []\n",
    "        fea_list = ['random', 'attention', \"scaled attention\", \"gradients\", \"ig\", \"deeplift\"] #\"gradientshap\", \n",
    "        for feat in fea_list:\n",
    "                suff.append(topk.AOPC_sufficiency[str(feat)].get('mean'))\n",
    "                comp.append(topk.AOPC_comprehensiveness[str(feat)].get('mean'))\n",
    "                \n",
    "                suff_std.append(topk.AOPC_sufficiency[str(feat)].get('std'))\n",
    "                comp_std.append(topk.AOPC_comprehensiveness[str(feat)].get('std'))\n",
    "        fea_list = ['Random', 'Attention', \"Scaled Attention\", \"Gradients\", \"Integrated Gradients\", \"Deeplift\"]\n",
    "        final_df = pd.DataFrame(list(zip(fea_list, suff, suff_std, comp, comp_std)),\n",
    "                columns =['Feature','AOPC NormSuff', 'std', 'AOPC NormComp', 'std'])\n",
    "        final_df['Dataset'] = str(dataset)\n",
    "\n",
    "        df = final_df.T\n",
    "        df = df.rename(columns=df.iloc[0]).drop(df.index[0])\n",
    "        df = df[:-1] # drop the las dataset name row\n",
    "\n",
    "        df['Attention'] = df['Attention']/df['Random']\n",
    "        df['Scaled Attention'] = df['Scaled Attention']/df['Random']\n",
    "        df['Gradients'] = df['Gradients']/df['Random']\n",
    "        df['Integrated Gradients'] = df['Integrated Gradients']/df['Random']\n",
    "        df['Deeplift'] = df['Deeplift']/df['Random']\n",
    "\n",
    "        pred_faith_dict = {}\n",
    "        pred_faith_dict['model'] = model_id\n",
    "        pred_faith_dict['model']['Attention_Suff'] = df['Attention']['AOPC NormSuff']\n",
    "        pred_faith_dict['model']['Scaled_Attention_Suff'] = df['Scaled Attention']['AOPC NormSuff']\n",
    "        pred_faith_dict['model']['Gradients_Suff'] = df['Gradients']['AOPC NormSuff']\n",
    "        pred_faith_dict['model']['Integrated_Gradients_Suff'] = df['Integrated Gradients']['AOPC NormSuff']\n",
    "        pred_faith_dict['model']['Deeplift_Suff'] = df['Deeplift']['AOPC NormSuff']\n",
    "\n",
    "\n",
    "        pred_faith_dict['model']['Attention_Comp'] = df['Attention']['AOPC NormComp']\n",
    "        pred_faith_dict['model']['Scaled_Attention_Comp'] = df['Scaled Attention']['AOPC NormComp']\n",
    "        pred_faith_dict['model']['Gradients_Comp'] = df['Gradients']['AOPC NormComp']\n",
    "        pred_faith_dict['model']['Integrated_Gradients_Comp'] = df['Integrated Gradients']['AOPC NormComp']\n",
    "        pred_faith_dict['model']['Deeplift_Comp'] = df['Deeplift']['AOPC NormComp']\n",
    "\n",
    "        if dataset == 'ChnSentiCorp' or dataset == 'ant' or dataset == 'csl': pred_faith_dict['Accuracy'] = pred_result\n",
    "        else: pred_faith_dict['model']['F1'] = pred_result\n",
    "        print(pred_faith_dict)\n",
    "        return pred_faith_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mChnSentiCorp\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmbert\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m mbert_ChnSentiCorp \u001b[39m=\u001b[39m get_dict(dataset, model_id)\n\u001b[1;32m      4\u001b[0m bert_ChnSentiCorp \u001b[39m=\u001b[39m get_dict(dataset, \u001b[39m'\u001b[39m\u001b[39mmbert\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m summary \u001b[39m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[2], line 45\u001b[0m, in \u001b[0;36mget_dict\u001b[0;34m(dataset, model_id)\u001b[0m\n\u001b[1;32m     43\u001b[0m pred_faith_dict \u001b[39m=\u001b[39m {}\n\u001b[1;32m     44\u001b[0m pred_faith_dict[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m model_id\n\u001b[0;32m---> 45\u001b[0m pred_faith_dict[\u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mAttention_Suff\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mAttention\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mAOPC NormSuff\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     46\u001b[0m pred_faith_dict[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mScaled_Attention_Suff\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mScaled Attention\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mAOPC NormSuff\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     47\u001b[0m pred_faith_dict[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mGradients_Suff\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mGradients\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mAOPC NormSuff\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "dataset = 'ChnSentiCorp'\n",
    "model_id = 'mbert'\n",
    "mbert_ChnSentiCorp = get_dict(dataset, model_id)\n",
    "bert_ChnSentiCorp = get_dict(dataset, 'mbert')\n",
    "summary = {}\n",
    "summary[dataset] = mbert_ChnSentiCorp\n",
    "summary[dataset] = bert_ChnSentiCorp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ChnSentiCorp': {'model': 'mbert',\n",
       "  'Attention_Suff': 1.0902327957363036,\n",
       "  'Scaled_Attention_Suff': 1.0884435049783747,\n",
       "  'Gradients_Suff': 1.0483311770328323,\n",
       "  'Integrated_Gradients_Suff': 1.1026349831942344,\n",
       "  'Deeplift_Suff': 1.025998869133796,\n",
       "  'Attention_Comp': 1.3710924885883555,\n",
       "  'Scaled_Attention_Comp': 1.3789226438370283,\n",
       "  'Gradients_Comp': 1.156845532531631,\n",
       "  'Integrated_Gradients_Comp': 1.3241123432705728,\n",
       "  'Deeplift_Comp': 1.1598957879910066,\n",
       "  'Accuracy': 0.8577777777777771}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ChnSentiCorp'\n",
    "model_id = 'mbert'\n",
    "model_folder = model_id + '_trained_models/' + dataset + '/'\n",
    "faithful_folder = model_id + '_faithfulness/' + dataset\n",
    "pred_folder = model_id + '_trained_models/' + dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'./{model_id}_faithfulness/{dataset}/topk-faithfulness-scores-average-description.json'\n",
    "topk = pd.read_json(file_path, orient ='index')\n",
    "topk.rename(columns = {'AOPC - sufficiency':'AOPC_sufficiency', 'AOPC - comprehensiveness':'AOPC_comprehensiveness'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'./{model_folder}/{model_id}_predictive_performances.json'\n",
    "pred = pd.read_json(file_path)\n",
    "if dataset == 'ChnSentiCorp' or dataset == 'ant' or dataset == 'csl':\n",
    "    pred_result = pred['mean-accuracy'].mean()\n",
    "else: pred_result = pred['mean-f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "suff = []\n",
    "comp = []\n",
    "suff_std = []\n",
    "comp_std = []\n",
    "fea_list = ['random', 'attention', \"scaled attention\", \"gradients\", \"ig\", \"deeplift\"] #\"gradientshap\", \n",
    "for feat in fea_list:\n",
    "        suff.append(topk.AOPC_sufficiency[str(feat)].get('mean'))\n",
    "        comp.append(topk.AOPC_comprehensiveness[str(feat)].get('mean'))\n",
    "        \n",
    "        suff_std.append(topk.AOPC_sufficiency[str(feat)].get('std'))\n",
    "        comp_std.append(topk.AOPC_comprehensiveness[str(feat)].get('std'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fea_list = ['Random', 'Attention', \"Scaled Attention\", \"Gradients\", \"Integrated Gradients\", \"Deeplift\"]\n",
    "final_df = pd.DataFrame(list(zip(fea_list, suff, suff_std, comp, comp_std)),\n",
    "        columns =['Feature','AOPC NormSuff', 'std', 'AOPC NormComp', 'std'])\n",
    "final_df['Dataset'] = str(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df.T\n",
    "df = df.rename(columns=df.iloc[0]).drop(df.index[0])\n",
    "# drop the las dataset name row\n",
    "df = df[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Attention'] = df['Attention']/df['Random']\n",
    "df['Scaled Attention'] = df['Scaled Attention']/df['Random']\n",
    "df['Gradients'] = df['Gradients']/df['Random']\n",
    "df['Integrated Gradients'] = df['Integrated Gradients']/df['Random']\n",
    "df['Deeplift'] = df['Deeplift']/df['Random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_faith_dict = {}\n",
    "pred_faith_dict['Attention_Suff'] = df['Attention']['AOPC NormSuff']\n",
    "pred_faith_dict['Scaled_Attention_Suff'] = df['Scaled Attention']['AOPC NormSuff']\n",
    "pred_faith_dict['Gradients_Suff'] = df['Gradients']['AOPC NormSuff']\n",
    "pred_faith_dict['Integrated_Gradients_Suff'] = df['Integrated Gradients']['AOPC NormSuff']\n",
    "pred_faith_dict['Deeplift_Suff'] = df['Deeplift']['AOPC NormSuff']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_faith_dict['Attention_Comp'] = df['Attention']['AOPC NormComp']\n",
    "pred_faith_dict['Scaled_Attention_Comp'] = df['Scaled Attention']['AOPC NormComp']\n",
    "pred_faith_dict['Gradients_Comp'] = df['Gradients']['AOPC NormComp']\n",
    "pred_faith_dict['Integrated_Gradients_Comp'] = df['Integrated Gradients']['AOPC NormComp']\n",
    "pred_faith_dict['Deeplift_Comp'] = df['Deeplift']['AOPC NormComp']\n",
    "\n",
    "\n",
    "if dataset == 'ChnSentiCorp' or dataset == 'ant' or dataset == 'csl':\n",
    "    pred_faith_dict['Accuracy'] = pred_result\n",
    "else: pred_faith_dict['F1'] = pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ChnSentiCorp': {'mbert': {'Attention_Suff': 1.0902327957363036,\n",
       "   'Scaled_Attention_Suff': 1.0884435049783747,\n",
       "   'Gradients_Suff': 1.0483311770328323,\n",
       "   'Integrated_Gradients_Suff': 1.1026349831942344,\n",
       "   'Deeplift_Suff': 1.025998869133796,\n",
       "   'Attention_Comp': 1.3710924885883555,\n",
       "   'Scaled_Attention_Comp': 1.3789226438370283,\n",
       "   'Gradients_Comp': 1.156845532531631,\n",
       "   'Integrated_Gradients_Comp': 1.3241123432705728,\n",
       "   'Deeplift_Comp': 1.1598957879910066,\n",
       "   'Accuracy': 0.8577777777777771}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred_faith_dict = {}\n",
    "model_pred_faith_dict[model_id] = pred_faith_dict\n",
    "\n",
    "dataset_model_pred_faith_dict = {}\n",
    "dataset_model_pred_faith_dict[dataset] = model_pred_faith_dict\n",
    "dataset_model_pred_faith_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.autocall.ZMQExitAutocall at 0x7ff2fb62b8d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "with open('results_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset_model_pred_faith_dict, f)\n",
    "        \n",
    "# with open('results_summary.pkl', 'rb') as f:\n",
    "#     loaded_dict = pickle.load(f)\n",
    "\n",
    "quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File ./posthoc_results/sst/topk-faithfulness-scores-average-description.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 44\u001b[0m\n\u001b[1;32m     38\u001b[0m     final_df[\u001b[39m'\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(dataset)\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m final_df\n\u001b[0;32m---> 44\u001b[0m df1 \u001b[39m=\u001b[39m generate_csv(dataset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msst\u001b[39;49m\u001b[39m'\u001b[39;49m, method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mZEROOUT\u001b[39;49m\u001b[39m'\u001b[39;49m, normal\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, std\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m)\n\u001b[1;32m     45\u001b[0m df2 \u001b[39m=\u001b[39m generate_csv(dataset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39magnews\u001b[39m\u001b[39m'\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mZEROOUT\u001b[39m\u001b[39m'\u001b[39m, normal\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, std\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[39m#df3 = generate_csv(dataset='multirc', method='ZEROOUT', normal=1, std=0.5)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39m#df4 = generate_csv(dataset='evinf', method='ZEROOUT', normal=1, std=0.5)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[58], line 3\u001b[0m, in \u001b[0;36mgenerate_csv\u001b[0;34m(dataset, method, normal, std)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_csv\u001b[39m(dataset, method, normal, std):\n\u001b[1;32m      2\u001b[0m     file_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./posthoc_results/\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m}\u001b[39;00m\u001b[39m/topk-faithfulness-scores-average-description.json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     topk \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(file_path, orient \u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mindex\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m     topk\u001b[39m.\u001b[39mrename(columns \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mAOPC - sufficiency\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mAOPC_sufficiency\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAOPC - comprehensiveness\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mAOPC_comprehensiveness\u001b[39m\u001b[39m'\u001b[39m}, inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     file_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./posthoc_results/\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmethod\u001b[39m}\u001b[39;00m\u001b[39m-faithfulness-scores-normal_\u001b[39m\u001b[39m{\u001b[39;00mnormal\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/eva/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/eva/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/eva/lib/python3.11/site-packages/pandas/io/json/_json.py:733\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39mif\u001b[39;00m convert_axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m orient \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    731\u001b[0m     convert_axes \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m json_reader \u001b[39m=\u001b[39m JsonReader(\n\u001b[1;32m    734\u001b[0m     path_or_buf,\n\u001b[1;32m    735\u001b[0m     orient\u001b[39m=\u001b[39;49morient,\n\u001b[1;32m    736\u001b[0m     typ\u001b[39m=\u001b[39;49mtyp,\n\u001b[1;32m    737\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    738\u001b[0m     convert_axes\u001b[39m=\u001b[39;49mconvert_axes,\n\u001b[1;32m    739\u001b[0m     convert_dates\u001b[39m=\u001b[39;49mconvert_dates,\n\u001b[1;32m    740\u001b[0m     keep_default_dates\u001b[39m=\u001b[39;49mkeep_default_dates,\n\u001b[1;32m    741\u001b[0m     numpy\u001b[39m=\u001b[39;49mnumpy,\n\u001b[1;32m    742\u001b[0m     precise_float\u001b[39m=\u001b[39;49mprecise_float,\n\u001b[1;32m    743\u001b[0m     date_unit\u001b[39m=\u001b[39;49mdate_unit,\n\u001b[1;32m    744\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    745\u001b[0m     lines\u001b[39m=\u001b[39;49mlines,\n\u001b[1;32m    746\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    747\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    748\u001b[0m     nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[1;32m    749\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    750\u001b[0m     encoding_errors\u001b[39m=\u001b[39;49mencoding_errors,\n\u001b[1;32m    751\u001b[0m )\n\u001b[1;32m    753\u001b[0m \u001b[39mif\u001b[39;00m chunksize:\n\u001b[1;32m    754\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m~/anaconda3/envs/eva/lib/python3.11/site-packages/pandas/io/json/_json.py:818\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlines:\n\u001b[1;32m    816\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnrows can only be passed if lines=True\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 818\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data_from_filepath(filepath_or_buffer)\n\u001b[1;32m    819\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/eva/lib/python3.11/site-packages/pandas/io/json/_json.py:874\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    866\u001b[0m     filepath_or_buffer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n\u001b[1;32m    867\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m    868\u001b[0m     \u001b[39misinstance\u001b[39m(filepath_or_buffer, \u001b[39mstr\u001b[39m)\n\u001b[1;32m    869\u001b[0m     \u001b[39mand\u001b[39;00m filepath_or_buffer\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    873\u001b[0m ):\n\u001b[0;32m--> 874\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mfilepath_or_buffer\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    876\u001b[0m \u001b[39mreturn\u001b[39;00m filepath_or_buffer\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File ./posthoc_results/sst/topk-faithfulness-scores-average-description.json does not exist"
     ]
    }
   ],
   "source": [
    "def generate_csv(dataset, method, normal, std):\n",
    "    file_path = f'./posthoc_results/{dataset}/topk-faithfulness-scores-average-description.json'\n",
    "    topk = pd.read_json(file_path, orient ='index')\n",
    "    topk.rename(columns = {'AOPC - sufficiency':'AOPC_sufficiency', 'AOPC - comprehensiveness':'AOPC_comprehensiveness'}, inplace = True)\n",
    "\n",
    "    file_path = f'./posthoc_results/{dataset}/{method}-faithfulness-scores-normal_{normal}.json'\n",
    "    soft = pd.read_json(file_path, orient ='index')\n",
    "    soft.rename(columns = {'sufficiencies @ 1.0':'SoftSuff', 'comprehensiveness @ 1.0':'SoftComp'}, inplace = True)\n",
    "    \n",
    "    suff = []\n",
    "    comp = []\n",
    "    soft_suff = []\n",
    "    soft_comp = []\n",
    "    suff_std = []\n",
    "    comp_std = []\n",
    "    soft_suff_std = []\n",
    "    soft_comp_std = []\n",
    "\n",
    "\n",
    "    fea_list = ['random', 'attention', \"scaled attention\", \"gradients\", \"ig\", \"deeplift\"] #\"gradientshap\", \n",
    "    for feat in fea_list:\n",
    "        suff.append(topk.AOPC_sufficiency[str(feat)].get('mean'))\n",
    "        comp.append(topk.AOPC_comprehensiveness[str(feat)].get('mean'))\n",
    "        soft_suff.append(soft.SoftSuff[str(feat)].get('mean'))\n",
    "        soft_comp.append(soft.SoftComp[str(feat)].get('mean'))\n",
    "\n",
    "        suff_std.append(topk.AOPC_sufficiency[str(feat)].get('std'))\n",
    "        comp_std.append(topk.AOPC_comprehensiveness[str(feat)].get('std'))\n",
    "        soft_suff_std.append(soft.SoftSuff[str(feat)].get('std'))\n",
    "        soft_comp_std.append(soft.SoftComp[str(feat)].get('std'))\n",
    "\n",
    "    fea_list = ['Random', 'Attention', \"Scaled Attention\", \"Gradients\", \"Integrated Gradients\", \"Deeplift\"]\n",
    "\n",
    "    final_df = pd.DataFrame(list(zip(fea_list, soft_suff, soft_suff_std, soft_comp, soft_comp_std, \n",
    "                                        suff, suff_std, comp, comp_std)),\n",
    "            columns =['Feature', 'Soft-NormSuff', 'std', 'Soft-NormComp', 'std', \n",
    "                                ' AOPC NormSuff', 'std', 'AOPC NormComp', 'std'])\n",
    "    final_df['Dataset'] = str(dataset)\n",
    "\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "df1 = generate_csv(dataset='sst', method='ZEROOUT', normal=1, std=0.5)\n",
    "df2 = generate_csv(dataset='agnews', method='ZEROOUT', normal=1, std=0.5)\n",
    "#df3 = generate_csv(dataset='multirc', method='ZEROOUT', normal=1, std=0.5)\n",
    "#df4 = generate_csv(dataset='evinf', method='ZEROOUT', normal=1, std=0.5)\n",
    "\n",
    "final_df = pd.concat([df1, df2])\n",
    "final_path = './posthoc_results/faithfulness_result.csv'\n",
    "print('saved csv: ', final_path)\n",
    "final_df.to_csv(final_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
